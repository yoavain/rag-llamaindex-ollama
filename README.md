# Retrieval Augmented Generation (RAG) using LlamaIndex.TS

### Retrieval Augmented Generation (RAG) using LlamaIndex.TS on a local LLM running on Ollama

Test use-case: Answering question about music songs lyrics

### Implemented vector storage: 
- [X] In memory
- [X] Local storage
- [X] Qdrant
- [ ] Milvus [WIP]

---

## References
[LlamaIndexTS repo](https://github.com/run-llama/LlamaIndexTS)  
[LlamaIndexTS docs](https://ts.llamaindex.ai/)  
[Concepts](https://ts.llamaindex.ai/getting_started/concepts)  
[Examples](https://github.com/run-llama/LlamaIndexTS/tree/main/examples)  
